{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8Y1mWZ23p0ZH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rgoa_ETmTPVs"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xht-FGA92vj1"
      },
      "outputs": [],
      "source": [
        "import faiss.contrib.torch_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we_QnPWm08TG"
      },
      "source": [
        "## Config and Data Generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8PX-7rQ70tqi"
      },
      "outputs": [],
      "source": [
        "class config:\n",
        "    data_path_train = 'dataset/Amazon/amazon_train.txt'\n",
        "    data_path_test = 'dataset/Amazon/amazon_test.txt'\n",
        "    GPUs = True\n",
        "    lr = 0.0001\n",
        "    max_l2 = 6\n",
        "    sparsity = 0.00002\n",
        "    feature_dim = 135909\n",
        "    n_classes = 670091\n",
        "    n_train = 490449\n",
        "    n_test = 153025\n",
        "    n_epochs = 20\n",
        "    batch_size = 256\n",
        "    test_batch_size = 256\n",
        "    hidden_dim = 126\n",
        "    log_file = 'SLIDE FAISS GPU only rebuild no update exponential'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TAMHRfqh510j"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    # Pick GPU if available else CPU\n",
        "    if torch.cuda.is_available() and config.GPUs:\n",
        "        return torch.device(\"cuda\")\n",
        "    else:\n",
        "        return torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YbtqZbtW_xOP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# If the runtime is connected to Colab Hosted runtime\n",
        "if \"COLAB_GPU\" in os.environ:\n",
        "    config.data_path_train = '/content/drive/MyDrive/Colab Datasets/Amazon/amazon_train.txt'\n",
        "    config.data_path_test = '/content/drive/MyDrive/Colab Datasets/Amazon/amazon_test.txt'\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dPZfSX0V54xL"
      },
      "outputs": [],
      "source": [
        "device = get_default_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5juvuhd6FoP",
        "outputId": "f1a3c568-87ac-4edb-c617-1125205b3d68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DjnG_cqM6XdB"
      },
      "outputs": [],
      "source": [
        "def to_device(data, device):\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eau2_7Lq8VGx"
      },
      "outputs": [],
      "source": [
        "batch_size = config.batch_size\n",
        "n_classes = config.n_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CEW8Ds7EDDFU"
      },
      "outputs": [],
      "source": [
        "from itertools import islice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5aTiYD3sAQdX"
      },
      "outputs": [],
      "source": [
        "def data_generator(file_name, batch_size, n_classes):\n",
        "    while True:\n",
        "        lines = []\n",
        "        with open(file_name,'r',encoding='utf-8') as f:\n",
        "            header = f.readline()  # ignore the header\n",
        "            while True:\n",
        "                temp = len(lines)\n",
        "                lines += list(islice(f,batch_size-temp))\n",
        "                if len(lines)!=batch_size:\n",
        "                    break\n",
        "                idxs_x, idxs_y = [], []\n",
        "                vals = []\n",
        "                y_idxs = []\n",
        "                labels_batch = []\n",
        "                y_batch = torch.zeros([batch_size, n_classes], dtype = torch.float32, device = device)\n",
        "                count = 0\n",
        "                for line in lines:\n",
        "                    itms = line.strip().split(' ')\n",
        "                    y_idxs = [int(itm) for itm in itms[0].split(',')]\n",
        "                    labels_batch.append(y_idxs)\n",
        "                    y_batch[count, y_idxs] = 1.0/len(y_idxs)\n",
        "                    temp_idxs_y = [int(itm.split(':')[0]) for itm in itms[1:]]\n",
        "                    temp_idxs_y.append(config.feature_dim)\n",
        "                    idxs_y += temp_idxs_y\n",
        "                    idxs_x += [count] * len(temp_idxs_y)\n",
        "                    vals += [float(itm.split(':')[1]) for itm in itms[1:]]\n",
        "                    vals.append(1.0)\n",
        "                    count += 1\n",
        "                lines = []\n",
        "                yield (idxs_x, idxs_y, vals, y_batch, labels_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4X2NyAMF0e2o"
      },
      "outputs": [],
      "source": [
        "def data_generator_tst(file_name, batch_size, n_classes):\n",
        "    while True:\n",
        "        lines = []\n",
        "        with open(file_name,'r',encoding='utf-8') as f:\n",
        "            header = f.readline()  # ignore the header\n",
        "            while True:\n",
        "                temp = len(lines)\n",
        "                lines += list(islice(f,batch_size-temp))\n",
        "                if len(lines)!=batch_size:\n",
        "                    break\n",
        "                idxs_x, idxs_y = [], []\n",
        "                vals = []\n",
        "                labels_batch = []\n",
        "                count = 0\n",
        "                for line in lines:\n",
        "                    itms = line.strip().split(' ')\n",
        "                    y_idxs = [int(itm) for itm in itms[0].split(',')]\n",
        "                    labels_batch.append(y_idxs)\n",
        "                    temp_idxs_y = [int(itm.split(':')[0]) for itm in itms[1:]]\n",
        "                    temp_idxs_y.append(config.feature_dim)\n",
        "                    idxs_y += temp_idxs_y\n",
        "                    idxs_x += [count] * len(temp_idxs_y)\n",
        "                    vals += [float(itm.split(':')[1]) for itm in itms[1:]]\n",
        "                    vals.append(1.0)\n",
        "                    count += 1\n",
        "                lines = []\n",
        "                yield (idxs_x, idxs_y, vals, labels_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU3aozEL1VX3"
      },
      "source": [
        "## Torch Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lIArsURGcWaM"
      },
      "outputs": [],
      "source": [
        "import faiss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "e6mlBOpb2Z8o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import math\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eM3OSJ-N3neL"
      },
      "outputs": [],
      "source": [
        "n_epochs = config.n_epochs\n",
        "n_train = config.n_train\n",
        "n_test = config.n_test\n",
        "n_check = 50\n",
        "steps_per_epoch = n_train // batch_size\n",
        "n_steps = config.n_epochs * steps_per_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "r4pgS52YNOMI"
      },
      "outputs": [],
      "source": [
        "train_data_generator = data_generator(config.data_path_train, batch_size = config.batch_size, n_classes = config.n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KdptGXt6Np7z"
      },
      "outputs": [],
      "source": [
        "W1 = torch.randn(config.feature_dim + 1, config.hidden_dim, requires_grad = False)\n",
        "W2 = torch.randn(config.hidden_dim + 1, config.n_classes, requires_grad = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "v8LfPBEc1NnN"
      },
      "outputs": [],
      "source": [
        "val = 2.0/math.sqrt(config.hidden_dim + 1 + config.n_classes)\n",
        "a = - 2 * val\n",
        "b = 2 * val\n",
        "W1 = nn.init.trunc_normal_(W1, a = a, b = b)\n",
        "W2 = nn.init.trunc_normal_(W2, a = a, b = b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uvZ7W-wpxnoO"
      },
      "outputs": [],
      "source": [
        "config.max_l2 = 3 * 11 * torch.max(torch.abs(W2)).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b9DkI3VxyDx",
        "outputId": "294134d2-939e-4136-a3e9-0617a84deb94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1612374451942742"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config.max_l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7beVlwrt7f6V"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    (W1, W2) = to_device((W1, W2), device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2A81MnxLhSMB"
      },
      "outputs": [],
      "source": [
        "W1.grad = W1.new_zeros(W1.shape)\n",
        "W2.grad = W2.new_zeros(W2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IyfN8YqUaL1",
        "outputId": "bc4eb0bc-4b21-4faf-f818-022d5eece027"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W1.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az35K3wbGT1Q",
        "outputId": "260edff6-6f67-40a0-8ca0-80c4d47ccf53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False False\n"
          ]
        }
      ],
      "source": [
        "print(W1.requires_grad, W2.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5mvPD3GrQ9wP"
      },
      "outputs": [],
      "source": [
        "adam_optim = torch.optim.Adam(params = (W1, W2), lr = config.lr)\n",
        "\n",
        "log_softmax = torch.nn.LogSoftmax(dim = 1)\n",
        "add_unity_col = torch.nn.ConstantPad1d((0, 1), value = 1.0)\n",
        "add_zero_col = torch.nn.ConstantPad1d((0, 1), value = 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "LgxQZmc_OwWV"
      },
      "outputs": [],
      "source": [
        "gpu_resources = faiss.StandardGpuResources()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DRUgVsQASlBi"
      },
      "outputs": [],
      "source": [
        "dim = (config.hidden_dim + 1) + 1\n",
        "nlist = 512\n",
        "nbits = 8\n",
        "m = 32\n",
        "metric = faiss.METRIC_INNER_PRODUCT\n",
        "quantizer = faiss.IndexFlatIP(dim)\n",
        "index = faiss.IndexIVFPQ(quantizer, dim, nlist, m, nbits, faiss.METRIC_INNER_PRODUCT)\n",
        "gpu_index = faiss.index_cpu_to_gpu(gpu_resources, 0, index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rTVVQj26XbkK"
      },
      "outputs": [],
      "source": [
        "rebuild_delay = 50\n",
        "decay_rate = 1.15\n",
        "steps_since_rebuild = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6y419ri8Wd1b"
      },
      "outputs": [],
      "source": [
        "gpu_index.nprobe = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZAopQcSDMd2",
        "outputId": "dc63889e-03fc-4ea6-9228-0738a679b1e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 0)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpu_index.metric_arg, gpu_index.metric_type # 0 means inner product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "oyxPItjNG3We"
      },
      "outputs": [],
      "source": [
        "def add_items_to_index(index, data, ids, return_data_only = False):\n",
        "    with torch.no_grad():\n",
        "        temp_items = torch.zeros(size = (data.shape[1], (config.hidden_dim + 1) + 1))\n",
        "        temp_items[:,:-1] = data.T / config.max_l2\n",
        "        temp_items[:, -1] = torch.sqrt(1.00 - torch.sum(temp_items.pow(2), dim = 1))\n",
        "        if not return_data_only:\n",
        "            index.add_with_ids(temp_items, ids = ids)\n",
        "        else:\n",
        "            return temp_items\n",
        "  \n",
        "def query_items_from_index(index, query, k):\n",
        "    with torch.no_grad():\n",
        "        aug_query = add_zero_col(query)\n",
        "        aug_query = torch.nn.functional.normalize(aug_query, p = 2, dim = 1)\n",
        "        return index.search(aug_query, k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXiM-DMxA9H5",
        "outputId": "12d8e7cf-4636-499c-f4ca-234b32bcb6b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpu_index.is_trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "jOlWRGmqtndY"
      },
      "outputs": [],
      "source": [
        "def rebuild_index(train_index = True):\n",
        "    global gpu_index\n",
        "\n",
        "    config.max_l2 = 3 * 11 * torch.max(torch.abs(W2)).item()\n",
        "\n",
        "    normalized_init_data = add_items_to_index(gpu_index, W2, torch.arange(config.n_classes), return_data_only=True)\n",
        "    gpu_index.train(normalized_init_data)\n",
        "    add_items_to_index(gpu_index, W2, ids = torch.arange(config.n_classes).type(torch.int64))\n",
        "    print(\"Index Rebuilt, max_l2: \", config.max_l2)\n",
        "    print(\"Rebuild delay\", rebuild_delay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q86GhE7nO6-",
        "outputId": "5516c670-bf4f-4218-c78e-f89119f74c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index Rebuilt, max_l2:  0.1612374451942742\n",
            "Rebuild delay 50\n"
          ]
        }
      ],
      "source": [
        "rebuild_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "-NaL7tX0YBKj"
      },
      "outputs": [],
      "source": [
        "def fit(train_dg, step):\n",
        "    global steps_since_rebuild, rebuild_delay, decay_rate\n",
        "    try:\n",
        "    # for v in range(1):\n",
        "        with torch.no_grad():\n",
        "            adam_optim.zero_grad()\n",
        "            idxs_x, idxs_y, vals, Y, labels = next(train_dg)\n",
        "            \n",
        "            # Feed Forward\n",
        "            input = to_device(torch.sparse_coo_tensor([idxs_x, idxs_y], vals, size = (batch_size, config.feature_dim + 1)), device)\n",
        "            A1 = torch.sparse.mm(input, W1)\n",
        "            A1 = add_unity_col(A1)\n",
        "            Z1 = torch.nn.functional.relu(A1)\n",
        "            # ## HNSW layer2 indices query logic\n",
        "            _, layer2_idxs = query_items_from_index(gpu_index, query = Z1, k = min(int(config.sparsity * config.batch_size * config.n_classes), 2048))\n",
        "            # print(layer2_idxs)\n",
        "            layer2_idxs = layer2_idxs.flatten()\n",
        "            labels = np.array([x for sub in labels for x in sub])\n",
        "            layer2_idxs = np.array(layer2_idxs.cpu())\n",
        "            layer2_idxs = np.union1d(layer2_idxs, labels)\n",
        "            if max(layer2_idxs) >= config.n_classes or min(layer2_idxs) < 0: \n",
        "                print(max(layer2_idxs), min(layer2_idxs))\n",
        "            layer2_idxs %= config.n_classes\n",
        "\n",
        "\n",
        "            #  Sparse Feed Forward\n",
        "            A2 = Z1 @ W2[:, layer2_idxs]\n",
        "\n",
        "            P = log_softmax(A2)\n",
        "            L = -P * Y[:, layer2_idxs]\n",
        "            L = torch.mean(torch.sum(L, dim = 1))\n",
        "\n",
        "            # Sparse Back Propagation\n",
        "            PL = torch.exp(P)\n",
        "            temp_B2_grad = (PL - Y[:, layer2_idxs])\n",
        "            W2.grad[:, layer2_idxs] = Z1.T @ temp_B2_grad\n",
        "            temp_B1_grad = temp_B2_grad @ W2[:, layer2_idxs].T\n",
        "            temp_B1_grad[A1 < 0] = 0\n",
        "            W1.grad = torch.sparse.mm(input.t(), temp_B1_grad[:, :-1])  \n",
        "\n",
        "            adam_optim.step()\n",
        "\n",
        "            steps_since_rebuild += 1\n",
        "            if steps_since_rebuild >= rebuild_delay:\n",
        "                rebuild_index()\n",
        "                steps_since_rebuild = 0\n",
        "                rebuild_delay = int( rebuild_delay * decay_rate )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Exception\")\n",
        "    finally:\n",
        "        return 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "uyTpC6XUWFIr"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "E09gs-KakLL2"
      },
      "outputs": [],
      "source": [
        "def evaluate(n_steps, test_dg):\n",
        "    accuracies = []\n",
        "    for h in range(n_steps):\n",
        "        idxs_x, idxs_y, vals, Y = next(test_dg)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            input = to_device(torch.sparse_coo_tensor([idxs_x, idxs_y], vals, size = (config.test_batch_size, config.feature_dim + 1)), device)\n",
        "            A1 = torch.sparse.mm(input, W1)\n",
        "            A1 = add_unity_col(A1)\n",
        "            Z1 = torch.nn.functional.relu(A1)\n",
        "            A2 = Z1 @ W2\n",
        "                \n",
        "            _, preds = torch.max(A2, dim = 1)\n",
        "            num_correct = 0\n",
        "            for j in range(A2.shape[0]):\n",
        "                if len(np.intersect1d(preds[j].cpu(), Y[j])) > 0:\n",
        "                    num_correct += 1\n",
        "\n",
        "            accuracies.append(num_correct / config.test_batch_size)\n",
        "    return np.mean(accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8YCOEZGVtKm",
        "outputId": "e39ce641-2443-41d2-b6cc-1e36b46f23a5"
      },
      "outputs": [],
      "source": [
        "total_time = 0\n",
        "begin_time = time.time()\n",
        "with open(config.log_file, 'a') as out:\n",
        "    losses = []\n",
        "    for step in range(n_steps):\n",
        "        if step % n_check == 0:\n",
        "            total_time += time.time() - begin_time\n",
        "            n_steps_val = n_test//batch_size\n",
        "            test_data_generator = data_generator_tst(config.data_path_test, config.test_batch_size, config.n_classes)\n",
        "            accuracy = evaluate(20, test_data_generator)\n",
        "            print('Step:{}  Total_Time:{}  Test_acc:{}'.format(step, total_time, accuracy), file = out)\n",
        "            print('Step:{}  Total_Time:{}  Test_acc:{}'.format(step, total_time, accuracy))\n",
        "            begin_time = time.time()\n",
        "        if step % steps_per_epoch == (steps_per_epoch - 1):\n",
        "            total_time += time.time() - begin_time\n",
        "            n_steps_val = n_test//batch_size\n",
        "            test_data_generator = data_generator_tst(config.data_path_test, config.test_batch_size, config.n_classes)\n",
        "            \n",
        "            accuracy = evaluate(n_steps_val, test_data_generator) #checking precision on the complete test data\n",
        "            print('OVERALL Step : {} Total_Time: {} Test_acc: {}'.format(step, total_time, accuracy), file = out)\n",
        "            print('OVERALL Step : {} Total_Time: {} Test_acc: {}'.format(step, total_time, accuracy))\n",
        "            begin_time = time.time()\n",
        "        loss = fit(train_data_generator, step)\n",
        "        losses.append(loss)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SLIDE FAISS GPU only rebuild no update exponential",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
