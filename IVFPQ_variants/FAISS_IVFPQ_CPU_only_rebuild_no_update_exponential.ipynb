{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8Y1mWZ23p0ZH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rgoa_ETmTPVs"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we_QnPWm08TG"
      },
      "source": [
        "## Config and Data Generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8PX-7rQ70tqi"
      },
      "outputs": [],
      "source": [
        "class config:\n",
        "    data_path_train = 'dataset/Amazon/amazon_train.txt'\n",
        "    data_path_test = 'dataset/Amazon/amazon_test.txt'\n",
        "    GPUs = True\n",
        "    num_threads = 44 # Only used when GPUs is empty string\n",
        "    lr = 0.0001\n",
        "    max_l2 = 6\n",
        "    sparsity = 0.00002\n",
        "    feature_dim = 135909\n",
        "    n_classes = 670091\n",
        "    n_train = 490449\n",
        "    n_test = 153025\n",
        "    n_epochs = 20\n",
        "    batch_size = 256\n",
        "    test_batch_size = 256\n",
        "    hidden_dim = 126\n",
        "    log_file = 'log_amz_faiss_ivfpq_gpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TAMHRfqh510j"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    # Pick GPU if available else CPU\n",
        "    if torch.cuda.is_available() and config.GPUs:\n",
        "        return torch.device(\"cuda\")\n",
        "    else:\n",
        "        return torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YbtqZbtW_xOP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# If the runtime is connected to Colab Hosted runtime\n",
        "if \"COLAB_GPU\" in os.environ:\n",
        "    config.data_path_train = '/content/drive/MyDrive/Colab Datasets/Amazon/amazon_train.txt'\n",
        "    config.data_path_test = '/content/drive/MyDrive/Colab Datasets/Amazon/amazon_test.txt'\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dPZfSX0V54xL"
      },
      "outputs": [],
      "source": [
        "device = get_default_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5juvuhd6FoP",
        "outputId": "2bd980a0-86c2-486c-a67a-b57f2b464a49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DjnG_cqM6XdB"
      },
      "outputs": [],
      "source": [
        "def to_device(data, device):\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eau2_7Lq8VGx"
      },
      "outputs": [],
      "source": [
        "batch_size = config.batch_size\n",
        "n_classes = config.n_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CEW8Ds7EDDFU"
      },
      "outputs": [],
      "source": [
        "from itertools import islice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5aTiYD3sAQdX"
      },
      "outputs": [],
      "source": [
        "def data_generator(file_name, batch_size, n_classes):\n",
        "    while True:\n",
        "        lines = []\n",
        "        with open(file_name,'r',encoding='utf-8') as f:\n",
        "            header = f.readline()  # ignore the header\n",
        "            while True:\n",
        "                temp = len(lines)\n",
        "                lines += list(islice(f,batch_size-temp))\n",
        "                if len(lines)!=batch_size:\n",
        "                    break\n",
        "                idxs_x, idxs_y = [], []\n",
        "                vals = []\n",
        "                y_idxs = []\n",
        "                labels_batch = []\n",
        "                y_batch = torch.zeros([batch_size, n_classes], dtype = torch.float32, device = device)\n",
        "                count = 0\n",
        "                for line in lines:\n",
        "                    itms = line.strip().split(' ')\n",
        "                    y_idxs = [int(itm) for itm in itms[0].split(',')]\n",
        "                    labels_batch.append(y_idxs)\n",
        "                    y_batch[count, y_idxs] = 1.0/len(y_idxs)\n",
        "                    temp_idxs_y = [int(itm.split(':')[0]) for itm in itms[1:]]\n",
        "                    temp_idxs_y.append(config.feature_dim)\n",
        "                    idxs_y += temp_idxs_y\n",
        "                    idxs_x += [count] * len(temp_idxs_y)\n",
        "                    vals += [float(itm.split(':')[1]) for itm in itms[1:]]\n",
        "                    vals.append(1.0)\n",
        "                    count += 1\n",
        "                lines = []\n",
        "                yield (idxs_x, idxs_y, vals, y_batch, labels_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4X2NyAMF0e2o"
      },
      "outputs": [],
      "source": [
        "def data_generator_tst(file_name, batch_size, n_classes):\n",
        "    while True:\n",
        "        lines = []\n",
        "        with open(file_name,'r',encoding='utf-8') as f:\n",
        "            header = f.readline()  # ignore the header\n",
        "            while True:\n",
        "                temp = len(lines)\n",
        "                lines += list(islice(f,batch_size-temp))\n",
        "                if len(lines)!=batch_size:\n",
        "                    break\n",
        "                idxs_x, idxs_y = [], []\n",
        "                vals = []\n",
        "                labels_batch = []\n",
        "                count = 0\n",
        "                for line in lines:\n",
        "                    itms = line.strip().split(' ')\n",
        "                    y_idxs = [int(itm) for itm in itms[0].split(',')]\n",
        "                    labels_batch.append(y_idxs)\n",
        "                    temp_idxs_y = [int(itm.split(':')[0]) for itm in itms[1:]]\n",
        "                    temp_idxs_y.append(config.feature_dim)\n",
        "                    idxs_y += temp_idxs_y\n",
        "                    idxs_x += [count] * len(temp_idxs_y)\n",
        "                    vals += [float(itm.split(':')[1]) for itm in itms[1:]]\n",
        "                    vals.append(1.0)\n",
        "                    count += 1\n",
        "                lines = []\n",
        "                yield (idxs_x, idxs_y, vals, labels_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU3aozEL1VX3"
      },
      "source": [
        "## Torch Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lIArsURGcWaM"
      },
      "outputs": [],
      "source": [
        "import faiss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "e6mlBOpb2Z8o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import math\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eM3OSJ-N3neL"
      },
      "outputs": [],
      "source": [
        "n_epochs = config.n_epochs\n",
        "n_train = config.n_train\n",
        "n_test = config.n_test\n",
        "n_check = 50\n",
        "# n_check = 1\n",
        "steps_per_epoch = n_train // batch_size\n",
        "n_steps = config.n_epochs * steps_per_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "r4pgS52YNOMI"
      },
      "outputs": [],
      "source": [
        "train_data_generator = data_generator(config.data_path_train, batch_size = config.batch_size, n_classes = config.n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KdptGXt6Np7z"
      },
      "outputs": [],
      "source": [
        "W1 = torch.randn(config.feature_dim + 1, config.hidden_dim, requires_grad = False)\n",
        "W2 = torch.randn(config.hidden_dim + 1, config.n_classes, requires_grad = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "v8LfPBEc1NnN"
      },
      "outputs": [],
      "source": [
        "val = 2.0/math.sqrt(config.hidden_dim + 1 + config.n_classes)\n",
        "a = - 2 * val\n",
        "b = 2 * val\n",
        "W1 = nn.init.trunc_normal_(W1, a = a, b = b)\n",
        "W2 = nn.init.trunc_normal_(W2, a = a, b = b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uvZ7W-wpxnoO"
      },
      "outputs": [],
      "source": [
        "config.max_l2 = 3 * 11 * torch.max(torch.abs(W2)).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b9DkI3VxyDx",
        "outputId": "7f7c616d-f67e-416b-96c4-6835f1202858"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1612374451942742"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config.max_l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7beVlwrt7f6V"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    (W1, W2) = to_device((W1, W2), device)\n",
        "# W1.requires_grad = True\n",
        "# W2.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2A81MnxLhSMB"
      },
      "outputs": [],
      "source": [
        "W1.grad = W1.new_zeros(W1.shape)\n",
        "W2.grad = W2.new_zeros(W2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IyfN8YqUaL1",
        "outputId": "a3dd2fd6-53fc-42d5-a9b1-d6e6a39bfbab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W1.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az35K3wbGT1Q",
        "outputId": "09af8cdd-9a0d-4417-f988-5339646c1ad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False False\n"
          ]
        }
      ],
      "source": [
        "print(W1.requires_grad, W2.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5mvPD3GrQ9wP"
      },
      "outputs": [],
      "source": [
        "adam_optim = torch.optim.Adam(params = (W1, W2), lr = config.lr)\n",
        "\n",
        "log_softmax = torch.nn.LogSoftmax(dim = 1)\n",
        "add_unity_col = torch.nn.ConstantPad1d((0, 1), value = 1.0)\n",
        "add_zero_col = torch.nn.ConstantPad1d((0, 1), value = 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LgxQZmc_OwWV"
      },
      "outputs": [],
      "source": [
        "gpu_resources = faiss.StandardGpuResources()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DRUgVsQASlBi"
      },
      "outputs": [],
      "source": [
        "dim = (config.hidden_dim + 1) + 1\n",
        "nlist = 512\n",
        "nbits = 8\n",
        "m = 32\n",
        "metric = faiss.METRIC_INNER_PRODUCT\n",
        "quantizer = faiss.IndexFlatIP(dim)\n",
        "index = faiss.IndexIVFPQ(quantizer, dim, nlist, m, nbits, faiss.METRIC_INNER_PRODUCT)\n",
        "gpu_index = index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "AxvkYVPVR0bB"
      },
      "outputs": [],
      "source": [
        "gpu_index.nprobe = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZAopQcSDMd2",
        "outputId": "09edcb50-181e-4594-cb98-07eb4b1e8fd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 0)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpu_index.metric_arg, gpu_index.metric_type # 0 means inner product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "oyxPItjNG3We"
      },
      "outputs": [],
      "source": [
        "def add_items_to_index(index, data, ids, return_data_only = False):\n",
        "    with torch.no_grad():\n",
        "        temp_items = torch.zeros(size = (data.shape[1], (config.hidden_dim + 1) + 1))\n",
        "        temp_items[:,:-1] = data.T / config.max_l2\n",
        "        temp_items[:, -1] = torch.sqrt(1.00 - torch.sum(temp_items.pow(2), dim = 1))\n",
        "        temp_items = np.array(temp_items)\n",
        "        if not return_data_only:\n",
        "            if not isinstance(ids, np.ndarray):\n",
        "                index.add_with_ids(temp_items, ids = np.array(ids.cpu()).astype(np.int64))\n",
        "            else:\n",
        "                index.add_with_ids(temp_items, ids = np.array(ids).astype(np.int64))\n",
        "        else:\n",
        "            return temp_items\n",
        "  \n",
        "def query_items_from_index(index, query, k):\n",
        "    with torch.no_grad():\n",
        "        aug_query = add_zero_col(query)\n",
        "        aug_query = torch.nn.functional.normalize(aug_query, p = 2, dim = 1)\n",
        "        aug_query = np.array(aug_query)\n",
        "        return index.search(aug_query, k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "FGpKjcHHxpB6"
      },
      "outputs": [],
      "source": [
        "rebuild_delay = 50\n",
        "decay_rate = 1.15\n",
        "steps_since_rebuild = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXiM-DMxA9H5",
        "outputId": "bd9d0a1a-326a-4bb3-aea5-00c2c09d4932"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpu_index.is_trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "jOlWRGmqtndY"
      },
      "outputs": [],
      "source": [
        "def rebuild_index(train_index = True):\n",
        "    global gpu_index\n",
        "\n",
        "    config.max_l2 = 3 * 11 * torch.max(torch.abs(W2)).item()\n",
        "\n",
        "    normalized_init_data = add_items_to_index(gpu_index, W2, torch.arange(config.n_classes), return_data_only=True)\n",
        "    normalized_init_data = np.array(normalized_init_data)\n",
        "    gpu_index.train(normalized_init_data)\n",
        "    add_items_to_index(gpu_index, W2, ids = np.arange(config.n_classes))\n",
        "    print(\"Index Rebuilt, max_l2: \", config.max_l2)\n",
        "    print(\"Rebuild delay\", rebuild_delay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q86GhE7nO6-",
        "outputId": "2e1c1947-ba44-4b25-f57e-3dd2d671c4ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index Rebuilt, max_l2:  0.1612374451942742\n",
            "Rebuild delay 50\n"
          ]
        }
      ],
      "source": [
        "rebuild_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "-NaL7tX0YBKj"
      },
      "outputs": [],
      "source": [
        "def fit(train_dg, step):\n",
        "        global steps_since_rebuild, rebuild_delay, decay_rate\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                adam_optim.zero_grad()\n",
        "                idxs_x, idxs_y, vals, Y, labels = next(train_dg)\n",
        "                \n",
        "                # Feed Forward\n",
        "                input = to_device(torch.sparse_coo_tensor([idxs_x, idxs_y], vals, size = (batch_size, config.feature_dim + 1)), device)\n",
        "                A1 = torch.sparse.mm(input, W1)\n",
        "                A1 = add_unity_col(A1)\n",
        "                Z1 = torch.nn.functional.relu(A1)\n",
        "                # ## HNSW layer2 indices query logic\n",
        "                _, layer2_idxs = query_items_from_index(gpu_index, query = Z1.cpu(), k = int(config.sparsity * config.batch_size * config.n_classes))\n",
        "                # print(layer2_idxs)\n",
        "                layer2_idxs = layer2_idxs.flatten()\n",
        "                labels = np.array([x for sub in labels for x in sub])\n",
        "                layer2_idxs = np.array(layer2_idxs)\n",
        "                layer2_idxs = np.union1d(layer2_idxs, labels)\n",
        "\n",
        "                if max(layer2_idxs) >= config.n_classes or min(layer2_idxs) < 0: \n",
        "                    print(max(layer2_idxs), min(layer2_idxs))\n",
        "                layer2_idxs %= config.n_classes\n",
        "\n",
        "\n",
        "                #  Sparse Feed Forward\n",
        "                A2 = Z1 @ W2[:, layer2_idxs]\n",
        "\n",
        "                P = log_softmax(A2)\n",
        "                L = -P * Y[:, layer2_idxs]\n",
        "                L = torch.mean(torch.sum(L, dim = 1))\n",
        "\n",
        "                # Sparse Back Propagation\n",
        "                PL = torch.exp(P)\n",
        "                temp_B2_grad = (PL - Y[:, layer2_idxs])\n",
        "                W2.grad[:, layer2_idxs] = Z1.T @ temp_B2_grad\n",
        "                temp_B1_grad = temp_B2_grad @ W2[:, layer2_idxs].T\n",
        "                temp_B1_grad[A1 < 0] = 0\n",
        "                W1.grad = torch.sparse.mm(input.t(), temp_B1_grad[:, :-1])  \n",
        "\n",
        "                adam_optim.step()\n",
        "\n",
        "                steps_since_rebuild += 1\n",
        "                if steps_since_rebuild >= rebuild_delay:\n",
        "                    rebuild_index()\n",
        "                    steps_since_rebuild = 0\n",
        "                    rebuild_delay = int( rebuild_delay * decay_rate )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"Exception\")\n",
        "            print(e)\n",
        "        finally:\n",
        "            return 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "uyTpC6XUWFIr"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "E09gs-KakLL2"
      },
      "outputs": [],
      "source": [
        "def evaluate(n_steps, test_dg):\n",
        "    accuracies = []\n",
        "    for h in range(n_steps):\n",
        "        idxs_x, idxs_y, vals, Y = next(test_dg)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            input = to_device(torch.sparse_coo_tensor([idxs_x, idxs_y], vals, size = (config.test_batch_size, config.feature_dim + 1)), device)\n",
        "            A1 = torch.sparse.mm(input, W1)\n",
        "            A1 = add_unity_col(A1)\n",
        "            Z1 = torch.nn.functional.relu(A1)\n",
        "            A2 = Z1 @ W2\n",
        "                \n",
        "            _, preds = torch.max(A2, dim = 1)\n",
        "            num_correct = 0\n",
        "            for j in range(A2.shape[0]):\n",
        "                if len(np.intersect1d(preds[j].cpu(), Y[j])) > 0:\n",
        "                    num_correct += 1\n",
        "\n",
        "            accuracies.append(num_correct / config.test_batch_size)\n",
        "    return np.mean(accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8YCOEZGVtKm",
        "outputId": "48cc6dde-f4e0-4042-8ca8-222a284be62d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step:0  Total_Time:0.0009860992431640625  Test_acc:0.0\n",
            "Index Rebuilt, max_l2:  0.32244317326694727\n",
            "Rebuild delay 50\n",
            "Step:50  Total_Time:26.56253695487976  Test_acc:0.0134765625\n",
            "Step:100  Total_Time:30.045524835586548  Test_acc:0.00859375\n",
            "Index Rebuilt, max_l2:  0.6073473505675793\n",
            "Rebuild delay 57\n",
            "Step:150  Total_Time:56.38411259651184  Test_acc:0.008203125\n",
            "Index Rebuilt, max_l2:  0.7743756137788296\n",
            "Rebuild delay 65\n",
            "Step:200  Total_Time:83.49229693412781  Test_acc:0.01796875\n",
            "Index Rebuilt, max_l2:  0.9347339998930693\n",
            "Rebuild delay 74\n",
            "Step:250  Total_Time:111.24041438102722  Test_acc:0.0197265625\n",
            "Step:300  Total_Time:115.46797561645508  Test_acc:0.01796875\n",
            "Index Rebuilt, max_l2:  1.168583169579506\n",
            "Rebuild delay 85\n",
            "Step:350  Total_Time:143.49398612976074  Test_acc:0.0216796875\n",
            "Step:400  Total_Time:148.12948346138  Test_acc:0.021484375\n",
            "Index Rebuilt, max_l2:  1.3420818485319614\n",
            "Rebuild delay 97\n",
            "Step:450  Total_Time:177.1778860092163  Test_acc:0.0251953125\n",
            "Step:500  Total_Time:182.1181423664093  Test_acc:0.0244140625\n",
            "Index Rebuilt, max_l2:  1.4961000680923462\n",
            "Rebuild delay 111\n",
            "Step:550  Total_Time:211.49838662147522  Test_acc:0.0263671875\n",
            "Step:600  Total_Time:216.91029238700867  Test_acc:0.0296875\n",
            "Step:650  Total_Time:222.34260988235474  Test_acc:0.0310546875\n",
            "Index Rebuilt, max_l2:  1.6633628904819489\n",
            "Rebuild delay 127\n",
            "Step:700  Total_Time:251.852552652359  Test_acc:0.030859375\n",
            "Step:750  Total_Time:257.6032588481903  Test_acc:0.0302734375\n",
            "Step:800  Total_Time:263.3540804386139  Test_acc:0.03046875\n",
            "Index Rebuilt, max_l2:  1.8863072097301483\n",
            "Rebuild delay 146\n",
            "Step:850  Total_Time:293.1433775424957  Test_acc:0.033984375\n",
            "Step:900  Total_Time:299.17017459869385  Test_acc:0.0365234375\n",
            "Step:950  Total_Time:305.22114872932434  Test_acc:0.0373046875\n",
            "Index Rebuilt, max_l2:  2.205560691654682\n",
            "Rebuild delay 167\n",
            "Step:1000  Total_Time:334.8564088344574  Test_acc:0.0416015625\n",
            "Step:1050  Total_Time:341.31861543655396  Test_acc:0.0388671875\n",
            "Step:1100  Total_Time:347.83407282829285  Test_acc:0.041796875\n",
            "Step:1150  Total_Time:354.3711144924164  Test_acc:0.0390625\n",
            "Index Rebuilt, max_l2:  2.505302980542183\n",
            "Rebuild delay 192\n",
            "Step:1200  Total_Time:383.9461724758148  Test_acc:0.04375\n",
            "Step:1250  Total_Time:390.84098505973816  Test_acc:0.046484375\n",
            "Step:1300  Total_Time:397.7886300086975  Test_acc:0.0474609375\n",
            "Step:1350  Total_Time:404.7669086456299  Test_acc:0.046875\n",
            "Index Rebuilt, max_l2:  2.7868477553129196\n",
            "Rebuild delay 220\n",
            "Step:1400  Total_Time:434.6585032939911  Test_acc:0.0470703125\n",
            "Step:1450  Total_Time:442.0047128200531  Test_acc:0.0509765625\n",
            "Step:1500  Total_Time:449.3634865283966  Test_acc:0.0474609375\n",
            "Step:1550  Total_Time:456.6961843967438  Test_acc:0.051171875\n",
            "Step:1600  Total_Time:464.080242395401  Test_acc:0.0486328125\n",
            "Index Rebuilt, max_l2:  2.853659011423588\n",
            "Rebuild delay 252\n",
            "Step:1650  Total_Time:495.77172350883484  Test_acc:0.0494140625\n",
            "Step:1700  Total_Time:503.4618728160858  Test_acc:0.0513671875\n",
            "Step:1750  Total_Time:511.1029007434845  Test_acc:0.0517578125\n",
            "Step:1800  Total_Time:518.7332398891449  Test_acc:0.053515625\n",
            "Step:1850  Total_Time:526.3353612422943  Test_acc:0.0537109375\n",
            "Step:1900  Total_Time:533.9306585788727  Test_acc:0.0572265625\n",
            "OVERALL Step : 1914 Total_Time: 536.0240480899811 Test_acc: 0.0551651486599665\n",
            "Index Rebuilt, max_l2:  2.922357067465782\n",
            "Rebuild delay 289\n",
            "Step:1950  Total_Time:565.9808855056763  Test_acc:0.0587890625\n",
            "Step:2000  Total_Time:573.9057347774506  Test_acc:0.0583984375\n",
            "Step:2050  Total_Time:581.8468997478485  Test_acc:0.06328125\n",
            "Step:2100  Total_Time:589.8008227348328  Test_acc:0.06484375\n",
            "Step:2150  Total_Time:597.7621557712555  Test_acc:0.066015625\n",
            "Step:2200  Total_Time:605.6327803134918  Test_acc:0.06796875\n",
            "Step:2250  Total_Time:613.4691762924194  Test_acc:0.070703125\n",
            "Index Rebuilt, max_l2:  3.115904286503792\n",
            "Rebuild delay 332\n",
            "Step:2300  Total_Time:645.8971748352051  Test_acc:0.0763671875\n",
            "Step:2350  Total_Time:654.0595488548279  Test_acc:0.0759765625\n",
            "Step:2400  Total_Time:662.2652416229248  Test_acc:0.0748046875\n",
            "Step:2450  Total_Time:670.353809595108  Test_acc:0.0783203125\n",
            "Step:2500  Total_Time:678.4323785305023  Test_acc:0.0814453125\n",
            "Step:2550  Total_Time:686.5471684932709  Test_acc:0.084375\n",
            "Step:2600  Total_Time:694.7196128368378  Test_acc:0.084375\n",
            "Index Rebuilt, max_l2:  3.185519926249981\n",
            "Rebuild delay 381\n",
            "Step:2650  Total_Time:726.0488178730011  Test_acc:0.0814453125\n",
            "Step:2700  Total_Time:734.451409816742  Test_acc:0.0828125\n",
            "Step:2750  Total_Time:742.713406085968  Test_acc:0.083203125\n",
            "Step:2800  Total_Time:750.9704763889313  Test_acc:0.0849609375\n",
            "Step:2850  Total_Time:759.31720662117  Test_acc:0.083203125\n",
            "Step:2900  Total_Time:767.5523080825806  Test_acc:0.08828125\n",
            "Step:2950  Total_Time:775.8698465824127  Test_acc:0.085546875\n",
            "Step:3000  Total_Time:784.204968214035  Test_acc:0.0880859375\n",
            "Step:3050  Total_Time:792.4154367446899  Test_acc:0.088671875\n",
            "Index Rebuilt, max_l2:  3.383660227060318\n",
            "Rebuild delay 438\n",
            "Step:3100  Total_Time:824.4635801315308  Test_acc:0.0919921875\n",
            "Step:3150  Total_Time:832.993777513504  Test_acc:0.0951171875\n",
            "Step:3200  Total_Time:841.5263373851776  Test_acc:0.091015625\n",
            "Step:3250  Total_Time:850.0721073150635  Test_acc:0.0939453125\n",
            "Step:3300  Total_Time:858.6289970874786  Test_acc:0.09453125\n",
            "Step:3350  Total_Time:867.2241568565369  Test_acc:0.0984375\n",
            "Step:3400  Total_Time:875.6964156627655  Test_acc:0.0978515625\n",
            "Step:3450  Total_Time:884.1875326633453  Test_acc:0.1013671875\n",
            "Step:3500  Total_Time:892.7447934150696  Test_acc:0.10234375\n",
            "Step:3550  Total_Time:901.2977519035339  Test_acc:0.1046875\n",
            "Index Rebuilt, max_l2:  3.8026711866259575\n",
            "Rebuild delay 503\n",
            "Step:3600  Total_Time:933.3420763015747  Test_acc:0.10625\n",
            "Step:3650  Total_Time:942.1048421859741  Test_acc:0.106640625\n",
            "Step:3700  Total_Time:950.7935240268707  Test_acc:0.1056640625\n",
            "Step:3750  Total_Time:959.6476671695709  Test_acc:0.1083984375\n",
            "Step:3800  Total_Time:968.3232157230377  Test_acc:0.106640625\n",
            "OVERALL Step : 3829 Total_Time: 973.339329957962 Test_acc: 0.10226915829145729\n",
            "Step:3850  Total_Time:977.1261796951294  Test_acc:0.1044921875\n",
            "Step:3900  Total_Time:985.9068269729614  Test_acc:0.109375\n",
            "Step:3950  Total_Time:994.5931723117828  Test_acc:0.1162109375\n",
            "Step:4000  Total_Time:1003.4491801261902  Test_acc:0.1162109375\n",
            "Step:4050  Total_Time:1012.2913312911987  Test_acc:0.1146484375\n",
            "Step:4100  Total_Time:1021.0453338623047  Test_acc:0.1181640625\n",
            "Step:4150  Total_Time:1029.8145112991333  Test_acc:0.1173828125\n",
            "Index Rebuilt, max_l2:  4.095886878669262\n",
            "Rebuild delay 578\n",
            "Step:4200  Total_Time:1062.3247985839844  Test_acc:0.1244140625\n",
            "Step:4250  Total_Time:1071.1750042438507  Test_acc:0.12109375\n",
            "Step:4300  Total_Time:1080.057131767273  Test_acc:0.123046875\n",
            "Step:4350  Total_Time:1088.9887557029724  Test_acc:0.1220703125\n",
            "Step:4400  Total_Time:1097.9128968715668  Test_acc:0.1208984375\n",
            "Step:4450  Total_Time:1106.7627816200256  Test_acc:0.124609375\n",
            "Step:4500  Total_Time:1115.6069309711456  Test_acc:0.1279296875\n",
            "Step:4550  Total_Time:1124.5718019008636  Test_acc:0.1267578125\n",
            "Step:4600  Total_Time:1133.4598734378815  Test_acc:0.1255859375\n",
            "Step:4650  Total_Time:1142.2771589756012  Test_acc:0.130078125\n",
            "Step:4700  Total_Time:1151.165359735489  Test_acc:0.1255859375\n",
            "Step:4750  Total_Time:1160.018052816391  Test_acc:0.119921875\n",
            "Step:4800  Total_Time:1168.81689620018  Test_acc:0.1259765625\n",
            "Index Rebuilt, max_l2:  4.205677539110184\n",
            "Rebuild delay 664\n",
            "Step:4850  Total_Time:1200.759878396988  Test_acc:0.1275390625\n",
            "Step:4900  Total_Time:1209.6967306137085  Test_acc:0.1287109375\n",
            "Step:4950  Total_Time:1218.6249542236328  Test_acc:0.1271484375\n",
            "Step:5000  Total_Time:1227.6092600822449  Test_acc:0.131640625\n",
            "Step:5050  Total_Time:1236.5227785110474  Test_acc:0.1296875\n",
            "Step:5100  Total_Time:1245.5591142177582  Test_acc:0.1267578125\n",
            "Step:5150  Total_Time:1254.6425385475159  Test_acc:0.1326171875\n",
            "Step:5200  Total_Time:1263.7140653133392  Test_acc:0.13125\n",
            "Step:5250  Total_Time:1272.7098729610443  Test_acc:0.1349609375\n",
            "Step:5300  Total_Time:1281.6877207756042  Test_acc:0.13203125\n",
            "Step:5350  Total_Time:1290.7208933830261  Test_acc:0.132421875\n",
            "Step:5400  Total_Time:1299.8880467414856  Test_acc:0.1322265625\n",
            "Step:5450  Total_Time:1308.8608376979828  Test_acc:0.1376953125\n",
            "Step:5500  Total_Time:1317.8035593032837  Test_acc:0.1388671875\n",
            "Step:5550  Total_Time:1326.7129771709442  Test_acc:0.1396484375\n",
            "Index Rebuilt, max_l2:  4.529049575328827\n",
            "Rebuild delay 763\n",
            "Step:5600  Total_Time:1359.1215462684631  Test_acc:0.1408203125\n",
            "Step:5650  Total_Time:1368.3041770458221  Test_acc:0.143359375\n",
            "Step:5700  Total_Time:1377.4694168567657  Test_acc:0.1427734375\n",
            "OVERALL Step : 5744 Total_Time: 1385.425712108612 Test_acc: 0.13012327261306533\n",
            "Step:5750  Total_Time:1386.5573592185974  Test_acc:0.1412109375\n",
            "Step:5800  Total_Time:1395.7652986049652  Test_acc:0.1404296875\n",
            "Step:5850  Total_Time:1404.8363897800446  Test_acc:0.14140625\n",
            "Step:5900  Total_Time:1414.119980096817  Test_acc:0.144140625\n",
            "Step:5950  Total_Time:1423.3854990005493  Test_acc:0.141796875\n",
            "Step:6000  Total_Time:1432.5709323883057  Test_acc:0.140625\n",
            "Step:6050  Total_Time:1441.808525800705  Test_acc:0.146875\n",
            "Step:6100  Total_Time:1451.0362720489502  Test_acc:0.147265625\n",
            "Step:6150  Total_Time:1460.365033864975  Test_acc:0.1439453125\n",
            "Step:6200  Total_Time:1469.6340780258179  Test_acc:0.1435546875\n",
            "Step:6250  Total_Time:1478.8402693271637  Test_acc:0.1474609375\n",
            "Step:6300  Total_Time:1488.1156792640686  Test_acc:0.1470703125\n",
            "Step:6350  Total_Time:1497.338213443756  Test_acc:0.1458984375\n",
            "Step:6400  Total_Time:1506.416669845581  Test_acc:0.14609375\n",
            "Step:6450  Total_Time:1515.6070759296417  Test_acc:0.14921875\n",
            "Index Rebuilt, max_l2:  4.936027452349663\n",
            "Rebuild delay 877\n",
            "Step:6500  Total_Time:1548.1454179286957  Test_acc:0.1494140625\n",
            "Step:6550  Total_Time:1557.3940436840057  Test_acc:0.1458984375\n",
            "Step:6600  Total_Time:1566.7246062755585  Test_acc:0.1427734375\n",
            "Step:6650  Total_Time:1577.1017110347748  Test_acc:0.1423828125\n",
            "Step:6700  Total_Time:1586.391354084015  Test_acc:0.14453125\n",
            "Step:6750  Total_Time:1595.6001846790314  Test_acc:0.1501953125\n",
            "Step:6800  Total_Time:1604.9007422924042  Test_acc:0.1494140625\n",
            "Step:6850  Total_Time:1614.1767029762268  Test_acc:0.1509765625\n",
            "Step:6900  Total_Time:1623.4490940570831  Test_acc:0.1525390625\n",
            "Step:6950  Total_Time:1632.6408269405365  Test_acc:0.15234375\n",
            "Step:7000  Total_Time:1641.9447910785675  Test_acc:0.1548828125\n",
            "Step:7050  Total_Time:1651.2271883487701  Test_acc:0.1548828125\n",
            "Step:7100  Total_Time:1660.4852244853973  Test_acc:0.1501953125\n",
            "Step:7150  Total_Time:1669.798883676529  Test_acc:0.155078125\n",
            "Step:7200  Total_Time:1679.2490215301514  Test_acc:0.15625\n",
            "Step:7250  Total_Time:1689.1735155582428  Test_acc:0.151953125\n",
            "Step:7300  Total_Time:1698.6297235488892  Test_acc:0.1533203125\n",
            "Step:7350  Total_Time:1708.0363421440125  Test_acc:0.1552734375\n",
            "Step:7400  Total_Time:1717.5930604934692  Test_acc:0.1568359375\n",
            "Step:7450  Total_Time:1726.929761648178  Test_acc:0.1544921875\n",
            "Index Rebuilt, max_l2:  5.43888446688652\n",
            "Rebuild delay 1008\n",
            "Step:7500  Total_Time:1759.4334225654602  Test_acc:0.1533203125\n",
            "Step:7550  Total_Time:1768.8875813484192  Test_acc:0.1548828125\n",
            "Step:7600  Total_Time:1778.371414899826  Test_acc:0.156640625\n",
            "Step:7650  Total_Time:1787.7449357509613  Test_acc:0.1541015625\n",
            "OVERALL Step : 7659 Total_Time: 1789.4045886993408 Test_acc: 0.14997513609715243\n",
            "Step:7700  Total_Time:1797.1874430179596  Test_acc:0.1552734375\n",
            "Step:7750  Total_Time:1806.4781498908997  Test_acc:0.15703125\n",
            "Step:7800  Total_Time:1815.9844453334808  Test_acc:0.1568359375\n",
            "Step:7850  Total_Time:1825.379004240036  Test_acc:0.15625\n",
            "Step:7900  Total_Time:1834.7927114963531  Test_acc:0.1572265625\n",
            "Step:7950  Total_Time:1844.208979845047  Test_acc:0.1619140625\n",
            "Step:8000  Total_Time:1853.6763243675232  Test_acc:0.1619140625\n",
            "Step:8050  Total_Time:1863.1746499538422  Test_acc:0.165234375\n",
            "Step:8100  Total_Time:1872.6401088237762  Test_acc:0.166015625\n",
            "Step:8150  Total_Time:1882.0681200027466  Test_acc:0.1626953125\n",
            "Step:8200  Total_Time:1891.5068144798279  Test_acc:0.1638671875\n",
            "Step:8250  Total_Time:1900.9106659889221  Test_acc:0.164453125\n",
            "Step:8300  Total_Time:1910.269093990326  Test_acc:0.16484375\n",
            "Step:8350  Total_Time:1919.7407276630402  Test_acc:0.1654296875\n",
            "Step:8400  Total_Time:1929.270361661911  Test_acc:0.1662109375\n",
            "Step:8450  Total_Time:1938.7753925323486  Test_acc:0.1646484375\n",
            "Step:8500  Total_Time:1948.1118590831757  Test_acc:0.1701171875\n",
            "Step:8550  Total_Time:1957.5359933376312  Test_acc:0.1712890625\n",
            "Step:8600  Total_Time:1967.006151676178  Test_acc:0.1689453125\n",
            "Index Rebuilt, max_l2:  7.872228920459747\n",
            "Rebuild delay 1159\n",
            "Step:8650  Total_Time:1999.4536187648773  Test_acc:0.171484375\n",
            "Step:8700  Total_Time:2008.983528137207  Test_acc:0.173828125\n",
            "Step:8750  Total_Time:2018.4691543579102  Test_acc:0.17578125\n",
            "Step:8800  Total_Time:2027.904965877533  Test_acc:0.1712890625\n",
            "Step:8850  Total_Time:2037.3293557167053  Test_acc:0.1732421875\n",
            "Step:8900  Total_Time:2046.8880877494812  Test_acc:0.1734375\n",
            "Step:8950  Total_Time:2056.3679826259613  Test_acc:0.1724609375\n",
            "Step:9000  Total_Time:2065.9101796150208  Test_acc:0.172265625\n",
            "Step:9050  Total_Time:2075.357134103775  Test_acc:0.1720703125\n",
            "Step:9100  Total_Time:2084.874549150467  Test_acc:0.1767578125\n",
            "Step:9150  Total_Time:2094.3063333034515  Test_acc:0.1681640625\n",
            "Step:9200  Total_Time:2103.829920053482  Test_acc:0.1681640625\n",
            "Step:9250  Total_Time:2113.37602686882  Test_acc:0.16640625\n",
            "Step:9300  Total_Time:2122.880211830139  Test_acc:0.1669921875\n",
            "Step:9350  Total_Time:2132.343808412552  Test_acc:0.1673828125\n",
            "Step:9400  Total_Time:2142.226237297058  Test_acc:0.16875\n",
            "Step:9450  Total_Time:2151.7112205028534  Test_acc:0.174609375\n",
            "Step:9500  Total_Time:2161.5762746334076  Test_acc:0.17578125\n",
            "Step:9550  Total_Time:2171.236617088318  Test_acc:0.1740234375\n",
            "OVERALL Step : 9574 Total_Time: 2175.689910888672 Test_acc: 0.16623481993299832\n",
            "Step:9600  Total_Time:2180.668113708496  Test_acc:0.172265625\n",
            "Step:9650  Total_Time:2190.0924575328827  Test_acc:0.1724609375\n",
            "Step:9700  Total_Time:2199.584995031357  Test_acc:0.1732421875\n",
            "Step:9750  Total_Time:2209.082790374756  Test_acc:0.1763671875\n",
            "Step:9800  Total_Time:2218.614834547043  Test_acc:0.1732421875\n",
            "Step:9850  Total_Time:2228.071234703064  Test_acc:0.175390625\n",
            "Step:9900  Total_Time:2237.4434835910797  Test_acc:0.1701171875\n",
            "Step:9950  Total_Time:2247.0043108463287  Test_acc:0.17265625\n",
            "Index Rebuilt, max_l2:  8.613367080688477\n",
            "Rebuild delay 1332\n",
            "Step:10000  Total_Time:2279.7114634513855  Test_acc:0.1724609375\n",
            "Step:10050  Total_Time:2289.376855134964  Test_acc:0.1677734375\n",
            "Step:10100  Total_Time:2298.9462502002716  Test_acc:0.1677734375\n",
            "Step:10150  Total_Time:2308.49195933342  Test_acc:0.1689453125\n",
            "Step:10200  Total_Time:2318.1183788776398  Test_acc:0.169921875\n",
            "Step:10250  Total_Time:2327.7909274101257  Test_acc:0.1724609375\n",
            "Step:10300  Total_Time:2337.570620059967  Test_acc:0.17578125\n",
            "Step:10350  Total_Time:2347.1760914325714  Test_acc:0.1771484375\n",
            "Step:10400  Total_Time:2356.829650402069  Test_acc:0.175390625\n",
            "Step:10450  Total_Time:2366.434152841568  Test_acc:0.173828125\n",
            "Step:10500  Total_Time:2376.270069360733  Test_acc:0.1744140625\n",
            "Step:10550  Total_Time:2385.8324880599976  Test_acc:0.1744140625\n",
            "Step:10600  Total_Time:2395.4078261852264  Test_acc:0.180859375\n",
            "Step:10650  Total_Time:2404.899484395981  Test_acc:0.1798828125\n",
            "Step:10700  Total_Time:2414.462359905243  Test_acc:0.1810546875\n",
            "Step:10750  Total_Time:2423.927598953247  Test_acc:0.18359375\n",
            "Step:10800  Total_Time:2433.438469171524  Test_acc:0.1802734375\n"
          ]
        }
      ],
      "source": [
        "total_time = 0\n",
        "begin_time = time.time()\n",
        "with open(config.log_file, 'a') as out:\n",
        "    losses = []\n",
        "    for step in range(n_steps):\n",
        "        if step % n_check == 0:\n",
        "            total_time += time.time() - begin_time\n",
        "            n_steps_val = n_test//batch_size\n",
        "            test_data_generator = data_generator_tst(config.data_path_test, config.test_batch_size, config.n_classes)\n",
        "            accuracy = evaluate(20, test_data_generator)\n",
        "            print('Step:{}  Total_Time:{}  Test_acc:{}'.format(step, total_time, accuracy), file = out)\n",
        "            print('Step:{}  Total_Time:{}  Test_acc:{}'.format(step, total_time, accuracy))\n",
        "            begin_time = time.time()\n",
        "        if step % steps_per_epoch == (steps_per_epoch - 1):\n",
        "            total_time += time.time() - begin_time\n",
        "            n_steps_val = n_test//batch_size\n",
        "            test_data_generator = data_generator_tst(config.data_path_test, config.test_batch_size, config.n_classes)\n",
        "            \n",
        "            accuracy = evaluate(n_steps_val, test_data_generator) #checking precision on the complete test data\n",
        "            print('OVERALL Step : {} Total_Time: {} Test_acc: {}'.format(step, total_time, accuracy), file = out)\n",
        "            print('OVERALL Step : {} Total_Time: {} Test_acc: {}'.format(step, total_time, accuracy))\n",
        "            begin_time = time.time()\n",
        "        loss = fit(train_data_generator, step)\n",
        "        losses.append(loss)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SLIDE FAISS CPU",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
